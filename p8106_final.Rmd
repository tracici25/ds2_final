---
title: "Final" 
author: "Yuechen Liu, Mufeng Xu, Yanhao Li"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


\newpage

```{r}
library(tidyverse)
library(caret)
library(glmnet)
library(ISLR)
library(pls)
library(AppliedPredictiveModeling)
library(MASS)
library(e1071)
library(mlbench)
library(pROC)
library(arsenal)
library(visdat)
library(pdp)
library(vip)
library(randomForest)
library(ranger)
library(gbm)
library(e1071)
library(kernlab)

```

# Introduction

Stroke is a serious life-threatening medical condition. According to the World Health Organization, stroke is the second leading cause of death globally. To better understand which factors correlate to the stroke event, our group find a stroke prediction dataset. This dataset contains twelve columns. The first column labels the unique identifier of the patient. The last column records the occurrence of stroke by 1 (Yes) or 0 (No). The other ten columns contain the observations of possible predictors.

# Load, clean, and tidy data

```{r}
stroke = read_csv("./healthcare-dataset-stroke-data.csv") %>% 
  mutate(
    bmi = as.numeric(bmi)
  )

stroke1 = stroke %>% 
  janitor::clean_names() %>% 
  filter(
    bmi != "N/A"
  ) %>% 
  mutate(
    gender = recode(
      gender,
      "Male" = 0,
      "Female" = 1,
      "Other" = 2
    ),
    ever_married = recode(
      ever_married,
      "No" = 0,
      "Yes" = 1
    ),
    work_type = recode(
      work_type,
      "children" = 0,
      "Govt_job" = 1,
      "Never_worked" = 2,
      "Private" = 3,
      "Self-employed" = 4
    ),
    residence_type = recode(
      residence_type,
      "Rural" = 0,
      "Urban" = 1
    ),
    smoking_status = recode(
      smoking_status,
      "formerly smoked" = 0,
      "never smoked" = 1,
      "smokes" = 2,
      "Unknown" = 3
    ),
    stroke = as.factor(stroke)
  ) %>% 
  relocate(
    age, avg_glucose_level, bmi
  )

stroke2 = stroke1 %>% 
  mutate(
    gender = as.factor(gender),
    hypertension = as.factor(hypertension),
    heart_disease = as.factor(heart_disease),
    ever_married = as.factor(ever_married),
    work_type = as.factor(work_type),
    residence_type = as.factor(residence_type),
    smoking_status = as.factor(smoking_status)
  ) %>% 
  mutate(
    stroke = recode(
    stroke,
    '0' = 'No',
    '1' = 'Yes'
  )) %>% 
  filter(gender != 2)
```

# Exploratory analysis/ visualization

```{r}
stats = tableby(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data = stroke)

summary(stats, text = TRUE) %>% knitr::kable()

featurePlot(x = stroke1[, 1:3], 
            y = stroke1$stroke,
            scales = list(x = list(relation = "free"), 
                          y = list(relation = "free")),
            plot = "density",
            pch = "|", 
            auto.key = list(columns = 2),
            font = 2)
```

# Models

```{r}
set.seed(1)

indextrain <- createDataPartition(y = stroke2$stroke,
                               p = 0.8,
                               list = FALSE)

x <- stroke2[indextrain, -c(4, 12)]

y <- stroke2$stroke[indextrain]###train

x2 <- stroke2[-indextrain, -c(4, 12)]

y2 <- stroke2$stroke[-indextrain] ###test

ctrl <- trainControl(method = "cv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)


```

## GLM
```{r}
model.glm = train(x = x,
                  y = y,
                  method = 'glm',
                  metric = "ROC",
                 trControl = ctrl)


test.pred.prob = predict(model.glm, newdata = x2, type = "prob")[,1]
test.pred = rep("Yes", length(test.pred.prob))
test.pred[test.pred.prob<0.99] = "No"

confusionMatrix(data = as.factor(test.pred),
                reference = y2,
                positive = "Yes")
model.glm$bestTune

```

## MARS

```{r}
set.seed(1)
model.mars <- train(x = x,
                    y = y,
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:3, 
                                           nprune = 2:15),
                    metric = "ROC",
                    trControl = ctrl)

test.pred.prob = predict(model.mars, newdata = x2, type = "prob")[,1]
test.pred = rep("Yes", length(test.pred.prob))
test.pred[test.pred.prob<0.99] = "No"

confusionMatrix(data = as.factor(test.pred),
                reference = y2,
                positive = "Yes")
model.mars$bestTune

```


## GAM
```{r}
set.seed(1)
model.gam <- train(x = x,
                   y = y,
                   method = "gam",
                   metric = "ROC",
                   trControl = ctrl)

test.pred.prob = predict(model.gam, newdata = x2, type = "prob")[,1]
test.pred = rep("Yes", length(test.pred.prob))
test.pred[test.pred.prob<0.99] = "No"

confusionMatrix(data = as.factor(test.pred),
                reference = y2,
                positive = "Yes")
model.gam$bestTune

```

## LDA (from the midterm, LDA is the best among LDA, QDA and KNN)

```{r}
set.seed(1)
model.lda = train(x = data.matrix(x),
                  y = y,
                  method = "lda",
                  metric = "ROC",
                  trControl = ctrl)

test.pred.prob = predict(model.lda, newdata = data.matrix(x2), type = "prob")[,1]
test.pred = rep("Yes", length(test.pred.prob))
test.pred[test.pred.prob<0.99] = "No"

confusionMatrix(data = as.factor(test.pred),
                reference = y2,
                positive = "Yes")
model.lda$bestTune

```

## Random Forest
```{r}
rf.grid <- expand.grid(mtry = 1:10,
                       splitrule = "gini",
                       min.node.size = seq(from = 2, to = 10, by = 2))
set.seed(2)
model.rf <- train(x = x,
                  y = y,
                method = "ranger",
                tuneGrid = rf.grid,
                metric = "ROC",
                trControl = ctrl)

ggplot(model.rf, highlight = TRUE)

test.pred.prob = predict(model.rf, newdata = x2, type = "prob")[,1]
test.pred = rep("Yes", length(test.pred.prob))
test.pred[test.pred.prob<0.99] = "No"

confusionMatrix(data = as.factor(test.pred),
                reference = y2,
                positive = "Yes")
model.rf$bestTune

```


```{r}


```

```{r}


```

```{r}


```













